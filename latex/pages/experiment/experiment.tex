
    This section focuses on the implementation and the tests conducted to evaluate if the models work properly. This includes the data handling, logging, the training process, and the evaluation steps taken of the models. 


    \subsection{The Foundation of the Models}

    To build the models, a set of Python libraries is utilized, mainly PyTorch, NumPy, TensorBoard, and Einops. PyTorch serves as the core tool for constructing and training the models.
    
    The transformer model's code discussed in this thesis is based on a Python script by A. Karpathy named NanoGPT \autocite{nanoGPTkarpathy2023}. This script implements a straightforward LLM (Large Language Model) approach, and it has been modified to meet the specific needs of the discussed models. However, the underlying transformer architecture remains unchanged.
    
    \subsubsection{Data Handling}
    \label{sec:DataHandling}

    For data management, a script named dataSetCombiner is developed to load and return a combined dataset from specified image folders with optional transformations. The function combines the 33 different sources from multiple directories into a single dataset, also offering the option to apply various image transformations.
    
    It allows for the selection between the 512x512 and the 1024x1024 pixel dataset, depending on the use case. Parameters can be adjusted to tailor the dataset to specific needs, such as image size, the particular dataset to load, and the option to include multiple instances of the dataset. Furthermore, it can randomly flip images vertically or horizontally to augment the dataset, thereby preventing overfitting and improving model generalization. It also supports color jittering, allowing for random adjustments in image brightness, contrast, saturation, and hue, which introduces further variability into the dataset when needed. Additionally, an option to convert images to grayscale is available.
    

\begin{figure}[H]
\centering
\begin{lstlisting}[language=Python]
    def getDataSet(path, dataset_name, size_x, size_y, repeatData=1, random_vertical_flip=False, random_horizontal_flip=False, crop_type='random', grayscale=False, color_jitter=False, jitter_brightness=0, jitter_contrast=0, jitter_saturation=0, jitter_hue=0):
\end{lstlisting}
\caption{Python function declaration: getDataSet}
\label{fig:getDataSet}
\end{figure}


    \subsubsection{Monitoring Training Progress}
    
    The training process is monitored using TensorBoard, a tool that helps visualize different aspects of training. In this thesis, TensorBoard is particularly useful for tracking training and validation loss through plots. It also allows for the viewing of the input images and the outputs generated by the models.

    Secondly, the training progress is monitored by logging the training process. This is helpful because the console output is not accessible until the training has finished on the external Slurm cluster. Logging is performed using the Python logging library. Additionally, all hyperparameters are logged to the log file at the start of the scripts.

    %Todo : write about the logging the loss each 1000 steps val los train loss and the images


    \subsubsection{Multi GPU Training}
    
    To enhance the training speed of larger models, utilizing multiple GPUs can be significantly more efficient. Consequently, the model's code is adapted to support multi-GPU training while maintaining the original core structure. Necessary adjustments were made to the data DataLoader, logger, and trainer. For distributed training across multiple GPUs, the PyTorch library Distributed-Data-Parallel (DDP) is used. This implementation draws on guidelines from the PyTorch documentation \autocite{Subramanian2023}. The larger models are trained on an external Slurm cluster equipped with four A100 Tesla GPUs.



