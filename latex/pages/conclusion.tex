
    In conclusion, this thesis demonstrates the feasibility and potential of using transformer-based models for texture generation in video game development and use. The Column Image Transformer (CIT) and Spiral Image Transformer (SIT) represent initial approaches and potential ways in which traditional Transformer architectures can be extended beyond text to graphical content generation. Each model offers unique benefits and poses different challenges. Both models require further development to become fully user-friendly and capable of generating assets efficiently.

\subsection{Evaluation of the Models}

    As a general conclusion, the data suggest that it is possible to quickly generate new assets through this approach. Especially the CIT model can generate new assets in a short amount of time because it does not process the whole image at once and is highly parallelizable. However, this is also a significant disadvantage because it is unable to envision the whole context. In contrast, the Spiral Model, which can see the entire image at once, is unable to generate new assets quickly due to the fact that a context window will become exponentially large (width * height) and because the pixels depend on each other so each pixel needs to be generated after another. The best approach might be to find a middle ground between the two models. For example, using a wider width than in the CIT model or feeding additional information to the model, such as the x position of the pixel to be generated.

    Another addition to the model could be the use of text input as additional information. This would be an easy approach to generate more specific assets and it would be easier to start from no or a smaller amount of seed pixels, similar to DALL-E or Midjourney.

\subsubsection{Quality}
    The following images show generated assets from the CIT and the SIT model.
    
    

\subsubsection{Performance}

    A key question that arises is whether it is feasible to generate assets for video games using the developed models. This question can be divided into two distinct parts. The first considers the pre-generation of assets during the development cycle, while the second evaluates whether the models are efficient enough to generate assets in real time on a local machine.

    The following table provides a detailed overview of the performance metrics for the CIT and SIT models, tested both on GPU (CUDA) and the CPU. To be noted is that the Tokens column refers to the number of tokens used for the generation of the image. The CIT model uses a Batch size of 32 and a Context length of 32 tokens, while the SIT model uses a Batch size of 1 and a context length of 1024 tokens. Both models generate a resulting image of 32x32 pixels. Both models were tested on a local workstation with an NVIDIA GeForce RTX 3090 GPU and an AMD Ryzen 9 7900X CPU

    \begin{table}[H]
        \centering
        \small
        \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Model} & \textbf{Platform} & \textbf{Total Time (sec)} & \textbf{Avg Time per Token (sec)} & \textbf{Tokens} \\ \hline
        \multirow{2}{*}{CIT [1] 128} & GPU & 0.511 & 0.000499 & \multirow{2}{*}{32x32} \\ \cline{2-4}
                                           & CPU  & 0.494 & 0.000483 &  \\ \hline
        \multirow{2}{*}{CIT [3] 256} & GPU & 0.725 & 0.000708 & \multirow{2}{*}{32x32} \\ \cline{2-4}
                                           & CPU  & 2.851 & 0.002784 &  \\ \hline
        \multirow{2}{*}{CIT [4] 512} & GPU & 0.899 & 0.000877 & \multirow{2}{*}{32x32} \\ \cline{2-4}
                                           & CPU  & 4.489 & 0.004384 &  \\ \hline
        \multirow{2}{*}{SIT [5] Small} & GPU & 9.388 & 0.009168 & \multirow{2}{*}{1x1024} \\ \cline{2-4}
                                             & CPU  & 30.709 & 0.029989 &  \\ \hline
        \multirow{2}{*}{SIT [6] Big} & GPU & 15.773 & 0.015403 & \multirow{2}{*}{1x1024} \\ \cline{2-4}
                                           & CPU  & 114.394 & 0.111713 &  \\ \hline
        \end{tabular}
        \caption{Performance metrics for CIT and SIT models [local workstation]}
        \label{tab:performance_metrics}
    \end{table}
        
    The results show that the SIT model is significantly slower than the CIT model, especially when running on the CPU. This is due tu the fact that the processing in the Batch dimentions is way more efficient than in the Token dimension. TODO ADD INFO APPENDIX PLOT

    It can be said that both methods would be viable in a development environment, where the developer would generate assets in the prototyping or development cycle. The figure \autoref{fig:performanceTest} shows that the expected optimal runtime per pixels is 2.51ms for the sit model this would result in an runntime of ruffly 11 min for a 512x512 image on a 3090 RTX CARD.
    
    This could be a problem when thinking about to run these models on a avg gaming capable machine. Due to the vast amount of data and size of the models a big video memory is need. Only 27.17\% have more then 8 GB of VRAM and 49.37\% have at least a NVIDIA GeForce RTX 2060 more newer information form Steam Hard ware study March 2024 \autocite{Valve2024}. This could be a problem for the SIT model, which needs a lot of memory to run. The CIT   model could be run on most of the machines, but the quality of the generated images would be low and with a mentioned addition to the model, the requirements xould even be higher. So a cloud based solution could be a better approach for the case if someone wants to create a game with the capablity to generate asserts on the fly.


\subsection{Further research}

    The following sections outline potential areas for further research that could lead to significant improvements in model performance and usability and extend their applicability in real-world applications.

    \subsubsection{Discriminator}
    To achieve better results, a discriminator could be used to enhance the output of the model. In this context, a discriminator is a type of neural network trained to distinguish between real data and artificially generated data. The goal of the discriminator is to accurately classify data as either real from the actual dataset or fake, created by another neural network called the generator, in this case, the CIT or SIT Model. The discriminators performance helps improve the generator, leading to more realistic synthetic data over time. In a perfect scenario, the discriminator cannot distinguish between the generated content and the original content, and the loss will balance out at 0.5 for the discriminator. This is the point where the generator is creating content indistinguishable from the original content.

    Some tests have been conducted with a discriminator and the CIT model, where the CIT model was pretrained to learn basic generation and then further trained with the discriminator. The tests indicated that the performance of the CIT model could be slightly improved and needs further investigation.

    \subsubsection{Incorporating Text Input}

    Integrating text input into an image generation model like the CIT or SIT could significantly enhance its functionality and usability by allowing the model to generate images based on descriptive text prompts. Unfortunately, due to time constraints, this feature was not implemented in this thesis, but it could be a valuable addition to the models. To implement this, all the data would need to be additionally labeled with text descriptions. Most of the images already contain basic descriptions in their names, such as "concrete floor" or "oak wood tiling," but further labeling and more data would be required. This would allow the model to generate images based on text input. The text input could be used to generate more specific assets or to create assets from scratch without any seed pixels. This would make the model more usable in the development process of video games. Therefore, this could be a valuable addition to the models.

    \subsubsection{LLM Scaling Laws}

    As often mentioned in this thesis, the lack of training data and potentially the small size of the models could be reasons for the models not performing perfectly. The scaling laws of LLMs \autocite{kaplan2020scaling} could potentially be applied to the CIT and SIT models to improve their performance. The scaling laws of LLMs suggest that the performance of a model can be improved by increasing the models size and the amount of training data. This could be achieved by increasing the models parameter count and the amount of training data. One way would be to increase the number of attention heads or the size of the feedforward network, or the model could be enhanced by adding more transformer layers. 
    
    The amount of training data could also be increased by using more video game assets. In this thesis, 30 video games are used. Scaling up the training dataset and increasing the parameter count resulted in better results, especially for the SIT model.
