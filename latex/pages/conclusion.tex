
    In conclusion, this thesis demonstrates the feasibility and potential of using transformer-based models for texture generation in video game development and use. The Column Image Transformer (CIT) and Spiral Image Transformer (SIT) represent initial approaches and potential ways in which traditional Transformer architectures can be extended beyond text to graphical content generation. Each model offers unique benefits and poses different challenges. Both models require further development to become fully user-friendly and capable of generating assets efficiently.

\subsection{Evaluation of the Models}

    As a general conclusion, the data suggest that it is possible to quickly generate new assets through this approach. Especially the CIT model can generate new assets in a short amount of time because it does not process the whole image at once and is highly parallelizable. However, this is also a significant disadvantage because it is unable to envision the whole context. In contrast, the Spiral Model, which can see the entire image at once, is unable to generate new assets quickly due to the fact that a context window will become exponentially large (width * height) and because the pixels depend on each other so each pixel needs to be generated after another. The best approach might be to find a middle ground between the two models. For example, using a wider width than in the CIT model or feeding additional information to the model, such as the x position of the pixel to be generated.

    Another addition to the model could be the use of text input as additional information. This would be an easy approach to generate more specific assets and it would be easier to start from no or a smaller amount of seed pixels, similar to DALL-E or Midjourney.

\subsubsection{Quality}
    The following images show generated assets from the CIT and the SIT model.
    
    

\subsubsection{Performance}
    % One the big question is if it is possible to generated assets for video game. Here we can split it into two parts. The first part is to generate assets beforehand in the development cylce and in the second part is is the model so efficient that it is possible to generate assets in real time on a local machine.

    % \subsection{Execution locally and on the cloud}



\subsection{Further research}

    The following sections outline potential areas for further research that could lead to significant improvements in model performance and usability and extend their applicability in real-world applications.

    \subsubsection{Discriminator}
    To achieve better results, a discriminator could be used to enhance the output of the model. In this context, a discriminator is a type of neural network trained to distinguish between real data and artificially generated data. The goal of the discriminator is to accurately classify data as either real from the actual dataset or fake, created by another neural network called the generator, in this case, the CIT or SIT Model. The discriminators performance helps improve the generator, leading to more realistic synthetic data over time. In a perfect scenario, the discriminator cannot distinguish between the generated content and the original content, and the loss will balance out at 0.5 for the discriminator. This is the point where the generator is creating content indistinguishable from the original content.

    Some tests have been conducted with a discriminator and the CIT model, where the CIT model was pretrained to learn basic generation and then further trained with the discriminator. The tests indicated that the performance of the CIT model could be slightly improved and needs further investigation.

    \subsubsection{Incorporating Text Input}

    Integrating text input into an image generation model like the CIT or SIT could significantly enhance its functionality and usability by allowing the model to generate images based on descriptive text prompts. Unfortunately, due to time constraints, this feature was not implemented in this thesis, but it could be a valuable addition to the models. To implement this, all the data would need to be additionally labeled with text descriptions. Most of the images already contain basic descriptions in their names, such as "concrete floor" or "oak wood tiling," but further labeling and more data would be required. This would allow the model to generate images based on text input. The text input could be used to generate more specific assets or to create assets from scratch without any seed pixels. This would make the model more usable in the development process of video games. Therefore, this could be a valuable addition to the models.

    \subsubsection{LLM Scaling Laws}

    As often mentioned in this thesis, the lack of training data and potentially the small size of the models could be reasons for the models not performing perfectly. The scaling laws of LLMs \autocite{kaplan2020scaling} could potentially be applied to the CIT and SIT models to improve their performance. The scaling laws of LLMs suggest that the performance of a model can be improved by increasing the models size and the amount of training data. This could be achieved by increasing the models parameter count and the amount of training data. One way would be to increase the number of attention heads or the size of the feedforward network, or the model could be enhanced by adding more transformer layers. 
    
    The amount of training data could also be increased by using more video game assets. In this thesis, 30 video games are used. Scaling up the training dataset and increasing the parameter count resulted in better results, especially for the SIT model.
