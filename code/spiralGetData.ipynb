{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[63, 62, 61, 60, 59, 58, 57, 56],\n",
       " [36, 35, 34, 33, 32, 31, 30, 55],\n",
       " [37, 16, 15, 14, 13, 12, 29, 54],\n",
       " [38, 17, 4, 3, 2, 11, 28, 53],\n",
       " [39, 18, 5, 0, 1, 10, 27, 52],\n",
       " [40, 19, 6, 7, 8, 9, 26, 51],\n",
       " [41, 20, 21, 22, 23, 24, 25, 50],\n",
       " [42, 43, 44, 45, 46, 47, 48, 49]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create spiral matrix\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "def create_spiral(n):\n",
    "    # Initialize a n x n matrix\n",
    "    matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    x, y = 0, 0\n",
    "\n",
    "    # Direction vectors (right, down, left, up)\n",
    "    dx = [0, 1, 0, -1]\n",
    "    dy = [1, 0, -1, 0]\n",
    "    direction = 0\n",
    "\n",
    "    for i in range(n * n - 1, -1, -1):  # Start from n*n - 1 (35 for 6x6) and go down to 0\n",
    "        matrix[x][y] = i\n",
    "\n",
    "        nx = x + dx[direction]\n",
    "        ny = y + dy[direction]\n",
    "\n",
    "        # Change direction if next position is out of bounds or already filled\n",
    "        if nx < 0 or nx >= n or ny < 0 or ny >= n or matrix[nx][ny] != 0:\n",
    "            direction = (direction + 1) % 4  # Change direction\n",
    "            nx = x + dx[direction]\n",
    "            ny = y + dy[direction]\n",
    "\n",
    "        x, y = nx, ny\n",
    "\n",
    "    return matrix\n",
    "\n",
    "spiral_matrix = create_spiral(8)\n",
    "spiral_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[63, 62, 61, 60, 59, 58, 57, 56],\n",
      "        [36, 35, 34, 33, 32, 31, 30, 55],\n",
      "        [37, 16, 15, 14, 13, 12, 29, 54],\n",
      "        [38, 17,  4,  3,  2, 11, 28, 53],\n",
      "        [39, 18,  5,  0,  1, 10, 27, 52],\n",
      "        [40, 19,  6,  7,  8,  9, 26, 51],\n",
      "        [41, 20, 21, 22, 23, 24, 25, 50],\n",
      "        [42, 43, 44, 45, 46, 47, 48, 49]])\n",
      "tensor([[64, 68,  0, 60,  0,  6, 62, 48],\n",
      "        [49, 19,  1, 49, 85, 53,  7, 26],\n",
      "        [28,  6, 64, 61, 92, 73, 37, 43],\n",
      "        [94, 82, 53,  1, 68, 50, 62, 62],\n",
      "        [43, 47, 36,  7, 84,  9, 94, 77],\n",
      "        [73,  3, 65, 49,  2, 42, 54, 33],\n",
      "        [41, 74, 74, 50, 91,  4, 60, 66],\n",
      "        [53, 57, 49, 39, 12, 17, 95, 89]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 84, 68,  1, 53, 36, 65, 49,  2, 42,  9, 50, 73, 92, 61, 64,  6, 82,\n",
       "        47,  3, 74, 74, 50, 91,  4, 60, 54, 94, 62, 37,  7, 53, 85, 49,  1, 19,\n",
       "        49, 28, 94, 43, 73, 41, 53, 57, 49, 39, 12, 17, 95, 89, 66, 33, 77, 62,\n",
       "        43, 26, 48, 62,  6,  0, 60,  0, 68, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the spiral matrix to reorder the data tensor\n",
    "\n",
    "data_tensor = torch.randint(0, 99, (8, 8))\n",
    "\n",
    "spiral_indices = torch.tensor([\n",
    "    [63, 62, 61, 60, 59, 58, 57, 56],\n",
    "    [36, 35, 34, 33, 32, 31, 30, 55],\n",
    "    [37, 16, 15, 14, 13, 12, 29, 54],\n",
    "    [38, 17,  4,  3,  2, 11, 28, 53],\n",
    "    [39, 18,  5,  0,  1, 10, 27, 52],\n",
    "    [40, 19,  6,  7,  8,  9, 26, 51],\n",
    "    [41, 20, 21, 22, 23, 24, 25, 50],\n",
    "    [42, 43, 44, 45, 46, 47, 48, 49]\n",
    "])\n",
    "\n",
    "\n",
    "flattened_data = data_tensor.flatten()\n",
    "\n",
    "correct_reordered_tensor = torch.zeros_like(flattened_data)\n",
    "\n",
    "correct_reordered_tensor[spiral_indices.flatten()] = flattened_data\n",
    "\n",
    "correct_reordered_tensor = correct_reordered_tensor.reshape(8, 8).flatten()\n",
    "print(spiral_indices)\n",
    "print(data_tensor)\n",
    "correct_reordered_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[48, 47, 46, 45, 44, 43, 42],\n",
      "        [25, 24, 23, 22, 21, 20, 41],\n",
      "        [26,  9,  8,  7,  6, 19, 40],\n",
      "        [27, 10,  1,  0,  5, 18, 39],\n",
      "        [28, 11,  2,  3,  4, 17, 38],\n",
      "        [29, 12, 13, 14, 15, 16, 37],\n",
      "        [30, 31, 32, 33, 34, 35, 36]])\n",
      "tensor([[50, 58, 32, 62,  2,  5, 14],\n",
      "        [78, 93, 33, 34, 73, 41, 84],\n",
      "        [27, 37, 63, 92,  7,  2, 42],\n",
      "        [63, 97, 48, 33, 71, 78, 38],\n",
      "        [88, 71, 20, 66, 36, 56, 66],\n",
      "        [30, 69, 79, 79, 37, 40, 79],\n",
      "        [71, 85, 12, 74, 65, 55, 53]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([33, 48, 20, 66, 36, 71,  7, 92, 63, 37, 97, 71, 69, 79, 79, 37, 40, 56,\n",
       "        78,  2, 41, 73, 34, 33, 93, 78, 27, 63, 88, 30, 71, 85, 12, 74, 65, 55,\n",
       "        53, 79, 66, 38, 42, 84, 14,  5,  2, 62, 32, 58, 50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the spiral matrix to reorder the data tensor more efficiently\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "size = 7\n",
    "\n",
    "spiral_indices = torch.tensor(create_spiral(7))\n",
    "spiral_indices\n",
    "\n",
    "data_tensor = torch.randint(0, 99, (size,size))\n",
    "\n",
    "correct_reordered_tensor = torch.zeros_like(data_tensor.flatten())\n",
    "\n",
    "correct_reordered_tensor[spiral_indices.flatten()] = data_tensor.flatten()\n",
    "\n",
    "print(spiral_indices)\n",
    "print(data_tensor)\n",
    "correct_reordered_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n",
      "tensor([[[0.9529, 0.9529, 0.9529],\n",
      "         [0.9608, 0.9647, 0.9647],\n",
      "         [0.9686, 0.9686, 0.9647]],\n",
      "\n",
      "        [[0.8431, 0.8431, 0.8431],\n",
      "         [0.8510, 0.8549, 0.8549],\n",
      "         [0.8588, 0.8588, 0.8549]],\n",
      "\n",
      "        [[0.7490, 0.7490, 0.7490],\n",
      "         [0.7569, 0.7608, 0.7608],\n",
      "         [0.7647, 0.7647, 0.7608]]])\n",
      "torch.Size([3, 9])\n",
      "tensor([[8, 7, 6],\n",
      "        [1, 0, 5],\n",
      "        [2, 3, 4]])\n",
      "torch.Size([3, 9])\n",
      "tensor([[0.9647, 0.9608, 0.9686, 0.9686, 0.9647, 0.9647, 0.9529, 0.9529, 0.9529],\n",
      "        [0.8549, 0.8510, 0.8588, 0.8588, 0.8549, 0.8549, 0.8431, 0.8431, 0.8431],\n",
      "        [0.7608, 0.7569, 0.7647, 0.7647, 0.7608, 0.7608, 0.7490, 0.7490, 0.7490]])\n",
      "x torch.Size([8, 3])\n",
      "tensor([[0.9647, 0.8549, 0.7608],\n",
      "        [0.9608, 0.8510, 0.7569],\n",
      "        [0.9686, 0.8588, 0.7647],\n",
      "        [0.9686, 0.8588, 0.7647],\n",
      "        [0.9647, 0.8549, 0.7608],\n",
      "        [0.9647, 0.8549, 0.7608],\n",
      "        [0.9529, 0.8431, 0.7490],\n",
      "        [0.9529, 0.8431, 0.7490]])\n",
      "y torch.Size([8, 3])\n",
      "tensor([[0.9608, 0.8510, 0.7569],\n",
      "        [0.9686, 0.8588, 0.7647],\n",
      "        [0.9686, 0.8588, 0.7647],\n",
      "        [0.9647, 0.8549, 0.7608],\n",
      "        [0.9647, 0.8549, 0.7608],\n",
      "        [0.9529, 0.8431, 0.7490],\n",
      "        [0.9529, 0.8431, 0.7490],\n",
      "        [0.9529, 0.8431, 0.7490]])\n"
     ]
    }
   ],
   "source": [
    "# Use the spiral matrix to getData from an image\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "\n",
    "IMAGE_SIZE = 3\n",
    "BLOCK_SIZE = IMAGE_SIZE * IMAGE_SIZE - 1\n",
    "BATCH_SIZE = 0\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def create_spiral(n):\n",
    "    # Initialize a n x n matrix\n",
    "    matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    x, y = 0, 0\n",
    "\n",
    "    # Direction vectors (right, down, left, up)\n",
    "    dx = [0, 1, 0, -1]\n",
    "    dy = [1, 0, -1, 0]\n",
    "    direction = 0\n",
    "\n",
    "    for i in range(n * n - 1, -1, -1):  # Start from n*n - 1 (35 for 6x6) and go down to 0\n",
    "        matrix[x][y] = i\n",
    "\n",
    "        nx = x + dx[direction]\n",
    "        ny = y + dy[direction]\n",
    "\n",
    "        # Change direction if next position is out of bounds or already filled\n",
    "        if nx < 0 or nx >= n or ny < 0 or ny >= n or matrix[nx][ny] != 0:\n",
    "            direction = (direction + 1) % 4  # Change direction\n",
    "            nx = x + dx[direction]\n",
    "            ny = y + dy[direction]\n",
    "\n",
    "        x, y = nx, ny\n",
    "\n",
    "    return matrix\n",
    "\n",
    "spiral_indices = torch.tensor(create_spiral(IMAGE_SIZE))\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_data(data):\n",
    "    C ,H ,W = data.shape\n",
    "\n",
    "    print(data.shape)\n",
    "    print(data)\n",
    "\n",
    "    spiral_data = torch.zeros_like(data.view(C, -1))\n",
    "    print(spiral_data.shape)\n",
    "\n",
    "    spiral_data[:,spiral_indices.flatten()] = data.view(C, -1)\n",
    "\n",
    "    print(spiral_indices)\n",
    "\n",
    "    print(spiral_data.shape)\n",
    "    print(spiral_data)\n",
    "\n",
    "\n",
    "    x = spiral_data[:, :BLOCK_SIZE]\n",
    "    y = spiral_data[:, 1:BLOCK_SIZE+1]\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    x = rearrange(x, 'c h -> h c')\n",
    "    y = rearrange(y, 'c h -> h c')\n",
    "    return x, y\n",
    "\n",
    "\n",
    "with Image.open(\"gen_csgo.png\") as img:\n",
    "    img = transform(img)\n",
    "    dataRaw = img[:3].to(device)\n",
    "\n",
    "    x, y = get_data(dataRaw)\n",
    "\n",
    "    print(\"x\", x.shape)\n",
    "    print(x)\n",
    "    print(\"y\", y.shape)\n",
    "    print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34]])\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34]])\n"
     ]
    }
   ],
   "source": [
    "# convert back to image 1 Color channel\n",
    "\n",
    "import torch\n",
    "\n",
    "IMAGE_SIZE = 5\n",
    "\n",
    "def create_spiral(n):\n",
    "    # Initialize a n x n matrix\n",
    "    matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    x, y = 0, 0\n",
    "\n",
    "    # Direction vectors (right, down, left, up)\n",
    "    dx = [0, 1, 0, -1]\n",
    "    dy = [1, 0, -1, 0]\n",
    "    direction = 0\n",
    "\n",
    "    for i in range(n * n - 1, -1, -1):  # Start from n*n - 1 (35 for 6x6) and go down to 0\n",
    "        matrix[x][y] = i\n",
    "\n",
    "        nx = x + dx[direction]\n",
    "        ny = y + dy[direction]\n",
    "\n",
    "        # Change direction if next position is out of bounds or already filled\n",
    "        if nx < 0 or nx >= n or ny < 0 or ny >= n or matrix[nx][ny] != 0:\n",
    "            direction = (direction + 1) % 4  # Change direction\n",
    "            nx = x + dx[direction]\n",
    "            ny = y + dy[direction]\n",
    "\n",
    "        x, y = nx, ny\n",
    "\n",
    "    return matrix\n",
    "\n",
    "spiral_indices = torch.tensor(create_spiral(IMAGE_SIZE)).flatten()\n",
    "\n",
    "# Erstellen des Beispiel-Daten-Tensors und des spiralförmigen Index-Tensors (erneut)\n",
    "data_tensor = torch.arange(IMAGE_SIZE*IMAGE_SIZE).reshape(IMAGE_SIZE, IMAGE_SIZE) + 10\n",
    "\n",
    "# Erstellen des umgeordneten Tensors\n",
    "correct_reordered_tensor = torch.zeros_like(data_tensor.flatten())\n",
    "correct_reordered_tensor[spiral_indices] = data_tensor.flatten()\n",
    "\n",
    "\n",
    "positions_in_spiral = torch.argsort(spiral_indices)\n",
    "\n",
    "reconstructed_tensor_efficient = torch.zeros_like(data_tensor).flatten()\n",
    "reconstructed_tensor_efficient[positions_in_spiral] = correct_reordered_tensor\n",
    "\n",
    "# Rückumwandlung in 8x8 Format\n",
    "reconstructed_tensor_efficient = reconstructed_tensor_efficient.view(IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "print(data_tensor)\n",
    "print(reconstructed_tensor_efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAAnCAYAAACSeUteAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABjElEQVR4nO3YoUqeYRzG4ecTMRhFZMWgBhURy8CmSYNG08AyhhgMdoMgONgBiNGqSVHQJQ/AYJkDbXoIA5uG10OY4Q9fuK8rP9zvE97w4+l1Xdc1ACDWQL8vAAD0lxgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIN/jZgwdft0o/vDveK92b/XZYtvXjaaVsq7XWFq4nS/d2bs5K96ZvVkv3LmYuS/cm9u9L917+LpVtba4dlW211tr7l9PSvePz2n9v9ddG6d7b3Wzp3tjJ97Ktfz9r7/a0/Vq6d7v5u3RvcH64dG9vf7l0b/1qrGxraHSkbKu11h6e50v3/swtlu49Tkz994yXAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHC9ruu6fl8CAOgfLwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABDuA8LrKkew4jocAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5050, 0.2038, 0.3948],\n",
      "         [0.9407, 0.3153, 0.3985],\n",
      "         [0.0979, 0.6657, 0.9175],\n",
      "         [0.4840, 0.5062, 0.1831],\n",
      "         [0.6696, 0.2132, 0.3158],\n",
      "         [0.0860, 0.9279, 0.9758],\n",
      "         [0.2378, 0.6363, 0.2438],\n",
      "         [0.9242, 0.7957, 0.9378],\n",
      "         [0.0497, 0.2837, 0.7400],\n",
      "         [0.9288, 0.1126, 0.9831],\n",
      "         [0.2838, 0.4038, 0.5586],\n",
      "         [0.2642, 0.4961, 0.2088],\n",
      "         [0.8510, 0.1731, 0.3435],\n",
      "         [0.1241, 0.7069, 0.6697],\n",
      "         [0.0998, 0.4911, 0.8293],\n",
      "         [0.1859, 0.1069, 0.2074],\n",
      "         [0.1248, 0.6302, 0.3682],\n",
      "         [0.9691, 0.0310, 0.3165],\n",
      "         [0.7082, 0.3893, 0.0292],\n",
      "         [0.7239, 0.5672, 0.0691],\n",
      "         [0.1969, 0.0565, 0.3172],\n",
      "         [0.4920, 0.7544, 0.4033],\n",
      "         [0.5146, 0.8323, 0.4717],\n",
      "         [0.3401, 0.7028, 0.6494],\n",
      "         [0.1572, 0.8731, 0.8656]]])\n",
      "tensor([[[0.1572, 0.3401, 0.5146, 0.4920, 0.1969],\n",
      "         [0.9288, 0.0497, 0.9242, 0.2378, 0.7239],\n",
      "         [0.2838, 0.9407, 0.5050, 0.0860, 0.7082],\n",
      "         [0.2642, 0.0979, 0.4840, 0.6696, 0.9691],\n",
      "         [0.8510, 0.1241, 0.0998, 0.1859, 0.1248]],\n",
      "\n",
      "        [[0.8731, 0.7028, 0.8323, 0.7544, 0.0565],\n",
      "         [0.1126, 0.2837, 0.7957, 0.6363, 0.5672],\n",
      "         [0.4038, 0.3153, 0.2038, 0.9279, 0.3893],\n",
      "         [0.4961, 0.6657, 0.5062, 0.2132, 0.0310],\n",
      "         [0.1731, 0.7069, 0.4911, 0.1069, 0.6302]],\n",
      "\n",
      "        [[0.8656, 0.6494, 0.4717, 0.4033, 0.3172],\n",
      "         [0.9831, 0.7400, 0.9378, 0.2438, 0.0691],\n",
      "         [0.5586, 0.3985, 0.3948, 0.9758, 0.0292],\n",
      "         [0.2088, 0.9175, 0.1831, 0.3158, 0.3165],\n",
      "         [0.3435, 0.6697, 0.8293, 0.2074, 0.3682]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert back to image 3 colors\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch\n",
    "\n",
    "IMAGE_SIZE = 5\n",
    "\n",
    "def create_spiral(n):\n",
    "    # Initialize a n x n matrix\n",
    "    matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    x, y = 0, 0\n",
    "\n",
    "    # Direction vectors (right, down, left, up)\n",
    "    dx = [0, 1, 0, -1]\n",
    "    dy = [1, 0, -1, 0]\n",
    "    direction = 0\n",
    "\n",
    "    for i in range(n * n - 1, -1, -1):  # Start from n*n - 1 (35 for 6x6) and go down to 0\n",
    "        matrix[x][y] = i\n",
    "\n",
    "        nx = x + dx[direction]\n",
    "        ny = y + dy[direction]\n",
    "\n",
    "        # Change direction if next position is out of bounds or already filled\n",
    "        if nx < 0 or nx >= n or ny < 0 or ny >= n or matrix[nx][ny] != 0:\n",
    "            direction = (direction + 1) % 4  # Change direction\n",
    "            nx = x + dx[direction]\n",
    "            ny = y + dy[direction]\n",
    "\n",
    "        x, y = nx, ny\n",
    "\n",
    "    return matrix\n",
    "\n",
    "spiral_indices = torch.tensor(create_spiral(IMAGE_SIZE)).flatten()\n",
    "\n",
    "# Erstellen des Beispiel-Daten-Tensors und des spiralförmigen Index-Tensors (erneut)\n",
    "data_tensor = torch.rand((1,IMAGE_SIZE*IMAGE_SIZE,3))\n",
    "\n",
    "positions_in_spiral = torch.argsort(spiral_indices)\n",
    "\n",
    "reconstructed_tensor_efficient = torch.zeros((3,IMAGE_SIZE*IMAGE_SIZE))\n",
    "reconstructed_tensor_efficient[:,positions_in_spiral] = rearrange(data_tensor, '1 h c -> c h')\n",
    "\n",
    "# Rückumwandlung in 8x8 Format\n",
    "reconstructed_tensor_efficient = reconstructed_tensor_efficient.view(3,IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "plt.imshow(data_tensor)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(data_tensor)\n",
    "print(reconstructed_tensor_efficient)\n",
    "\n",
    "plt.imshow(rearrange(reconstructed_tensor_efficient, 'c h w -> h w c'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAAaCAYAAAAqnV8tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAA00lEQVR4nO3cUQrCMBBF0Ubd/4or4waiFhka9Z3zGQsTmJ9LKY6qqg0AiHVZfQEAYC0xAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEC42+Enx5ge79t1en5vOn/12/7k+l2zu+b23mk+2x7eP997J3v4dO7K2fbwHbPP2M+v7KF3P/PZR/5n2JsBAAgnBgAgnBgAgHBiAADCiQEACDeqjnxnCAD8K28GACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAg3AMg3FotfCH8hwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create expample image to explain the spiral matrix concept\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "size = 9\n",
    "\n",
    "def create_spiral(n):\n",
    "    # Initialize a n x n matrix\n",
    "    matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    x, y = 0, 0\n",
    "\n",
    "    # Direction vectors (right, down, left, up)\n",
    "    dx = [0, 1, 0, -1]\n",
    "    dy = [1, 0, -1, 0]\n",
    "    direction = 0\n",
    "\n",
    "    for i in range(n * n - 1, -1, -1):  # Start from n*n - 1 (35 for 6x6) and go down to 0\n",
    "        matrix[x][y] = i\n",
    "\n",
    "        nx = x + dx[direction]\n",
    "        ny = y + dy[direction]\n",
    "\n",
    "        # Change direction if next position is out of bounds or already filled\n",
    "        if nx < 0 or nx >= n or ny < 0 or ny >= n or matrix[nx][ny] != 0:\n",
    "            direction = (direction + 1) % 4  # Change direction\n",
    "            nx = x + dx[direction]\n",
    "            ny = y + dy[direction]\n",
    "\n",
    "        x, y = nx, ny\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def generate_color_gradient(length):\n",
    "    # Generate a gradient for each color channel\n",
    "    r = np.linspace(1, 0, length)\n",
    "    g = np.linspace(0, 0, length)  # Green channel remains constant at 0\n",
    "    b = np.linspace(0, 1, length)  # Blue channel increases from 0 to 1\n",
    "\n",
    "    # Stack the color channels to form the gradient\n",
    "    gradient = np.stack((r, g, b), axis=1)\n",
    "\n",
    "    return gradient\n",
    "\n",
    "\n",
    "spiral_indices = torch.tensor(create_spiral(size)).flatten()\n",
    "\n",
    "gradient_tensor = generate_color_gradient(size*size)\n",
    "\n",
    "gradient_tensor_reshaped = gradient_tensor[np.newaxis, :, :]\n",
    "\n",
    "# Plotting the color gradient\n",
    "plt.imshow(gradient_tensor_reshaped)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "gradient_tensor_reshaped_tensor = torch.tensor(gradient_tensor_reshaped).float()\n",
    "positions_in_spiral = torch.argsort(spiral_indices)\n",
    "\n",
    "reconstructed_tensor_efficient = torch.zeros((3,size*size))\n",
    "reconstructed_tensor_efficient[:,positions_in_spiral] = rearrange(gradient_tensor_reshaped_tensor, '1 h c -> c h')\n",
    "\n",
    "# Rückumwandlung in 8x8 Format\n",
    "reconstructed_tensor_efficient = reconstructed_tensor_efficient.view(3,size, size)\n",
    "\n",
    "\n",
    "plt.imshow(rearrange(reconstructed_tensor_efficient, 'c h w -> h w c'))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
