{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "BLOCK_SIZE: 128, BATCH_SIZE: 128, CHANNELS_IMG: 3, IMAGE_SIZE: 141, N_EMBD: 128\n",
      "Model has 1,217,867 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import ConcatDataset\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 128\n",
    "BLOCK_SIZE = 128\n",
    "IMAGE_SIZE = 129 + 12\n",
    "CHANNELS_IMG = 3\n",
    "\n",
    "N_EMBD = 128\n",
    "N_HEAD = 6\n",
    "N_LAYER = 6\n",
    "DROPOUT = 0.2\n",
    "\n",
    "VERSION = \"2.1.6.3_bigData\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def model_saveFile(version, train):\n",
    "    return f\"model/model{train}{VERSION}_FloorEP{version}.pth\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device: \",device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader):\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    for idx, (data, _) in enumerate(dataloader):\n",
    "        dataRaw = data.squeeze(0).to(device)\n",
    "        x, y = get_batch(dataRaw)\n",
    "        \n",
    "        _, loss = model(x, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_samples += 1\n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.query = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.value = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
    "\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, N_EMBD)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(DROPOUT),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "        \n",
    "class ColumnTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pixel_embedding = nn.Sequential(\n",
    "            nn.Linear(CHANNELS_IMG, N_EMBD//5, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(N_EMBD//5, N_EMBD//2, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(N_EMBD//2, N_EMBD, device = device),\n",
    "            nn.Dropout(DROPOUT),\n",
    "        )\n",
    "        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBD)\n",
    "        self.blocks = nn.Sequential(*[Block(N_EMBD, n_head=N_HEAD) for _ in range(N_LAYER)])\n",
    "        self.ln_f = nn.LayerNorm(N_EMBD) # final layer norm\n",
    "        self.lm_head = nn.Sequential(\n",
    "            nn.Linear(N_EMBD, N_EMBD//2, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(N_EMBD//2, N_EMBD//5, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(N_EMBD//5, CHANNELS_IMG, device=device),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, H, C = idx.shape\n",
    "        \n",
    "        tok_emb = self.pixel_embedding(idx) # (B, H, N_EMBD)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(H, device=device)) # (H, N_EMBD)\n",
    "\n",
    "        x = tok_emb + pos_emb # (B,H,N_EMBD)\n",
    "\n",
    "\n",
    "        x = self.blocks(x) # (B,H,N_EMBD)\n",
    "        x = self.ln_f(x) # (B,H,N_EMBD)\n",
    "        logits = self.lm_head(x) # (B,H,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # B, T, C = logits.shape\n",
    "            loss = F.mse_loss(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'BLOCK_SIZE: {BLOCK_SIZE}, BATCH_SIZE: {BATCH_SIZE}, CHANNELS_IMG: {CHANNELS_IMG}, IMAGE_SIZE: {IMAGE_SIZE}, N_EMBD: {N_EMBD}')\n",
    "\n",
    "m = ColumnTransformer()\n",
    "m = m.to(device)\n",
    "\n",
    "#print parameterscount\n",
    "print(f'Model has {count_parameters(m):,} trainable parameters')\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batch(data):\n",
    "    # C ,H ,W = data.shape\n",
    "\n",
    "    x = data[:, :BLOCK_SIZE, :BATCH_SIZE]\n",
    "    y = data[:, 1:BLOCK_SIZE*2+1, :BATCH_SIZE]\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    x = rearrange(x, 'c h b -> b h c')\n",
    "    y = rearrange(y, 'c h b -> b h c')\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "m = torch.load(f\"tempModel/modelpostTrain2.1.6.3_bigData_FloorEP0.pth\").to(device)\n",
    "\n",
    "def create_striped_tensor(width, height, stripe_width):\n",
    "    tensor = torch.zeros(1, 3, height, width, dtype=torch.uint8, device=device)\n",
    "\n",
    "    # Create stripes\n",
    "    for row in range(height):\n",
    "        if (row // stripe_width) % 2 != 0:\n",
    "            tensor[:, :, row, :] = 1  # White stripe\n",
    "\n",
    "    return tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"device: \",device)\n",
    "\n",
    "\n",
    "    zebra_tensor = rearrange(create_striped_tensor(width=64, height=64, stripe_width=2), '1 c h w -> 1 c h w')\n",
    "\n",
    "    # Displaying the tensor as an image\n",
    "    plt.imshow((rearrange(zebra_tensor, '1 c h w -> h w c')* 255).cpu().detach().numpy().astype('int'))\n",
    "    plt.axis('off')  # Turn off axis numbers\n",
    "    plt.show()\n",
    "\n",
    "    size_x = 128\n",
    "    size_y = 128\n",
    "\n",
    "    gen_length = 32\n",
    "\n",
    "\n",
    "    img_tensor = zebra_tensor.squeeze(0).to(device)\n",
    "    img_tensor = img_tensor[:3,:,:] # Remove alpha channel\n",
    "    \n",
    "    C, H, W = img_tensor.shape\n",
    "\n",
    "    img_gen = torch.zeros((C,H+gen_length,W)).to(device)\n",
    "    img_gen[:,:H,:] = img_tensor\n",
    "\n",
    "\n",
    "    for igen in range(gen_length):\n",
    "        \n",
    "        a = img_gen[:,igen:H+igen,:] # (C, H, W) \n",
    "        gen, _ = m(rearrange(a, 'c h w -> w h c')) # B, H, C \n",
    "\n",
    "        img_gen[:,H+igen,:] = rearrange(gen[:,-1,:], ' w c -> c w')\n",
    "\n",
    "    \n",
    "    img_gen = img_gen.squeeze(0) * 255\n",
    "    \n",
    "    image = rearrange(img_gen, 'c h w -> h w c').cpu().detach().numpy()\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    image[H-1, :6] = [255, 100, 255]\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Turn off axis numbers\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFB0lEQVR4nO3bMQrDMBQFQSnk/lf+6ba2CNiBzNTioW5RoT0zswBgrfV6+gIA/A5RACCiAEBEAYCIAgARBQAiCgBEFADI++rBvffR8MmfONv3bp/u2/5+3/a926f7/7J9hZcCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDZMzNPXwKA3+ClAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAPiBfOwOhpVrIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "m = torch.load(f\"tempModel/modelpostTrain2.1.6.3_bigData_FloorEP0.pth\").to(device)\n",
    "\n",
    "def create_striped_tensor(width, height, stripe_width):\n",
    "    tensor = torch.zeros(1, 3, height, width, dtype=torch.uint8, device=device)\n",
    "\n",
    "    # Create stripes\n",
    "    for row in range(height):\n",
    "        if (row // stripe_width) % 2 != 0:\n",
    "            tensor[:, :, row, :] = 1  # White stripe\n",
    "\n",
    "    return tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"device: \",device)\n",
    "\n",
    "\n",
    "    zebra_tensor = rearrange(create_striped_tensor(width=64, height=64, stripe_width=2), '1 c h w -> 1 c w h')\n",
    "\n",
    "    # Displaying the tensor as an image\n",
    "    plt.imshow((rearrange(zebra_tensor, '1 c h w -> h w c')* 255).cpu().detach().numpy().astype('int'))\n",
    "    plt.axis('off')  # Turn off axis numbers\n",
    "    plt.show()\n",
    "\n",
    "    size_x = 128\n",
    "    size_y = 128\n",
    "\n",
    "    gen_length = 32\n",
    "\n",
    "\n",
    "    img_tensor = zebra_tensor.squeeze(0).to(device)\n",
    "    img_tensor = img_tensor[:3,:,:] # Remove alpha channel\n",
    "    \n",
    "    C, H, W = img_tensor.shape\n",
    "\n",
    "    img_gen = torch.zeros((C,H+gen_length,W)).to(device)\n",
    "    img_gen[:,:H,:] = img_tensor\n",
    "\n",
    "\n",
    "    for igen in range(gen_length):\n",
    "        \n",
    "        a = img_gen[:,igen:H+igen,:] # (C, H, W) \n",
    "        gen, _ = m(rearrange(a, 'c h w -> w h c')) # B, H, C \n",
    "\n",
    "        img_gen[:,H+igen,:] = rearrange(gen[:,-1,:], ' w c -> c w')\n",
    "\n",
    "    \n",
    "    img_gen = img_gen.squeeze(0) * 255\n",
    "    \n",
    "    image = rearrange(img_gen, 'c h w -> h w c').cpu().detach().numpy()\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    image[H-1, :6] = [255, 100, 255]\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Turn off axis numbers\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
